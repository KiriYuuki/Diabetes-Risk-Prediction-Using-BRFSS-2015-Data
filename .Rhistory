list = FALSE,
times = 1)
diabetesTrain <- diabetesUS[ trainIndex,]
diabetesTest  <- diabetesUS[-trainIndex,]
# Logistic regression model
logistic_model <- glm(Diabetes ~ ., data = diabetesTrain, family = binomial)
summary(logistic_model)
# Predictions on the test set
logistic_pred <- predict(logistic_model, diabetesTest, type = "response")
logistic_pred_class <- ifelse(logistic_pred > 0.5, 1, 0)
# Confusion matrix
confusionMatrix(as.factor(logistic_pred_class), diabetesTest$Diabetes)
## Recursive Feature Elimination
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
results <- rfe(diabetesTrain[, -1], diabetesTrain$Diabetes, sizes=c(1:10), rfeControl=control)
install.packages("randomForest")
## Recursive Feature Elimination
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
results <- rfe(diabetesTrain[, -1], diabetesTrain$Diabetes, sizes=c(1:10), rfeControl=control)
## Recursive Feature Elimination
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
results <- rfe(diabetesTrain[, -1], diabetesTrain$Diabetes, sizes=c(1:10), rfeControl=control)
# Print the results
print(results)
predictors(results)
# Plot the results
plot(results, type=c("g", "o"))
knitr::opts_chunk$set(echo = TRUE)
# Load necessary libraries
library(tidyverse)
library(caret)
# Import the data
diabetesUS <- read.csv("data_input/diabetes_012_health_indicators_BRFSS2015.csv")
# Display the first few rows of the data
head(diabetesUS)
tail(diabetesUS)
dim(diabetesUS)
names(diabetesUS)
# Checking data types and converting to appropriate types
str(diabetesUS)
# Checking for missing values
colSums(is.na(diabetesUS))
anyNA(diabetesUS)
# Converting target variable to factor
diabetesUS$Diabetes_012 <- as.factor(diabetesUS$Diabetes_012)
str(diabetesUS)
# Renaming target variable for consistency
names(diabetes_data)[names(diabetes_data) == "Diabetes_012"] <- "Diabetes"
# Selecting and renaming relevant columns based on their actual names in the dataset
relevant_columns <- c("Diabetes", "HighBP", "HighChol", "CholCheck", "BMI", "Smoker",
"Stroke", "HeartDiseaseorAttack", "PhysActivity", "Fruits", "Veggies",
"HvyAlcoholConsump", "AnyHealthcare", "NoDocbcCost", "GenHlth",
"MentHlth", "PhysHlth", "DiffWalk", "Sex", "Age", "Education", "Income")
# Subset the data to include only the relevant columns
diabetes_data <- diabetes_data %>% select(all_of(relevant_columns))
# Renaming columns for easier access if needed (already consistent in this case)
names(diabetes_data) <- c("Diabetes", "HighBP", "HighChol", "CholCheck", "BMI", "Smoker",
"Stroke", "HeartDisease", "PhysActivity", "Fruit", "Veg", "Alcohol",
"HealthCoverage", "CostDoc", "GenHealth", "MentalHealth", "PhysicalHealth",
"DiffWalk", "Sex", "Age", "Education", "Income")
# Checking the structure again after subsetting and renaming
str(diabetes_data)
## Descriptive Statistics
summary(diabetesUS)
# Example of calculating mean and median for some key features
mean(diabetesUS$BMI)
median(diabetesUS$BMI)
# Example of a bar plot for the target variable distribution
ggplot(diabetesUS, aes(x=Diabetes)) + geom_bar()
# Example of a box plot for BMI by diabetes status
ggplot(diabetesUS, aes(x=Diabetes, y=BMI)) + geom_boxplot()
# Example of a scatter plot for Age vs BMI by diabetes status
ggplot(diabetesUS, aes(x=Age, y=BMI, color=Diabetes)) + geom_point()
# Split the data into training and testing sets
set.seed(123)
trainIndex <- createDataPartition(diabetesUS$Diabetes, p = .8,
list = FALSE,
times = 1)
diabetesTrain <- diabetesUS[ trainIndex,]
diabetesTest  <- diabetesUS[-trainIndex,]
# Logistic regression model
logistic_model <- glm(Diabetes ~ ., data = diabetesTrain, family = binomial)
summary(logistic_model)
# Predictions on the test set
logistic_pred <- predict(logistic_model, diabetesTest, type = "response")
logistic_pred_class <- ifelse(logistic_pred > 0.5, 1, 0)
# Confusion matrix
confusionMatrix(as.factor(logistic_pred_class), diabetesTest$Diabetes)
## Recursive Feature Elimination
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
results <- rfe(diabetesTrain[, -1], diabetesTrain$Diabetes, sizes=c(1:10), rfeControl=control)
# Print the results
print(results)
predictors(results)
knitr::opts_chunk$set(echo = TRUE)
# Load necessary libraries
library(tidyverse)
library(caret)
# Import the data
diabetesUS <- read.csv("data_input/diabetes_012_health_indicators_BRFSS2015.csv")
knitr::opts_chunk$set(echo = TRUE)
# Load necessary libraries
library(tidyverse)
library(caret)
# Import the data
diabetesUS <- read.csv("data_input/diabetes_012_health_indicators_BRFSS2015.csv")
# Display the first few rows of the data
head(diabetesUS)
tail(diabetesUS)
dim(diabetesUS)
names(diabetesUS)
# Checking data types and converting to appropriate types
str(diabetesUS)
# Checking for missing values
colSums(is.na(diabetesUS))
anyNA(diabetesUS)
# Converting target variable to factor
diabetesUS$Diabetes_012 <- as.factor(diabetesUS$Diabetes_012)
str(diabetesUS)
# Renaming target variable for consistency
names(diabetes_data)[names(diabetes_data) == "Diabetes_012"] <- "Diabetes"
# Selecting and renaming relevant columns based on their actual names in the dataset
relevant_columns <- c("Diabetes", "HighBP", "HighChol", "CholCheck", "BMI", "Smoker",
"Stroke", "HeartDiseaseorAttack", "PhysActivity", "Fruits", "Veggies",
"HvyAlcoholConsump", "AnyHealthcare", "NoDocbcCost", "GenHlth",
"MentHlth", "PhysHlth", "DiffWalk", "Sex", "Age", "Education", "Income")
# Subset the data to include only the relevant columns
diabetes_data <- diabetes_data %>% select(all_of(relevant_columns))
# Renaming columns for easier access if needed (already consistent in this case)
names(diabetes_data) <- c("Diabetes", "HighBP", "HighChol", "CholCheck", "BMI", "Smoker",
"Stroke", "HeartDisease", "PhysActivity", "Fruit", "Veg", "Alcohol",
"HealthCoverage", "CostDoc", "GenHealth", "MentalHealth", "PhysicalHealth",
"DiffWalk", "Sex", "Age", "Education", "Income")
# Checking the structure again after subsetting and renaming
str(diabetes_data)
## Descriptive Statistics
summary(diabetesUS)
# Example of calculating mean and median for some key features
mean(diabetesUS$BMI)
median(diabetesUS$BMI)
# Example of a bar plot for the target variable distribution
ggplot(diabetesUS, aes(x=Diabetes)) + geom_bar()
# Example of a box plot for BMI by diabetes status
ggplot(diabetesUS, aes(x=Diabetes, y=BMI)) + geom_boxplot()
# Example of a scatter plot for Age vs BMI by diabetes status
ggplot(diabetesUS, aes(x=Age, y=BMI, color=Diabetes)) + geom_point()
# Split the data into training and testing sets
set.seed(123)
trainIndex <- createDataPartition(diabetesUS$Diabetes, p = .8,
list = FALSE,
times = 1)
diabetesTrain <- diabetesUS[ trainIndex,]
diabetesTest  <- diabetesUS[-trainIndex,]
# Logistic regression model
logistic_model <- glm(Diabetes ~ ., data = diabetesTrain, family = binomial)
summary(logistic_model)
# Predictions on the test set
logistic_pred <- predict(logistic_model, diabetesTest, type = "response")
logistic_pred_class <- ifelse(logistic_pred > 0.5, 1, 0)
# Confusion matrix
confusionMatrix(as.factor(logistic_pred_class), diabetesTest$Diabetes)
knitr::opts_chunk$set(echo = TRUE)
# Load necessary libraries
library(tidyverse)
library(caret)
# Import the data
diabetesUS <- read.csv("data_input/diabetes_012_health_indicators_BRFSS2015.csv")
# Display the first few rows of the data
head(diabetesUS)
tail(diabetesUS)
dim(diabetesUS)
names(diabetesUS)
# Checking data types and converting to appropriate types
str(diabetesUS)
# Checking for missing values
colSums(is.na(diabetesUS))
anyNA(diabetesUS)
# Converting target variable to factor
diabetesUS$Diabetes_012 <- as.factor(diabetesUS$Diabetes_012)
str(diabetesUS)
# Renaming target variable for consistency
names(diabetesUS)[names(diabetesUS) == "Diabetes_012"] <- "Diabetes"
# Selecting and renaming relevant columns based on their actual names in the dataset
relevant_columns <- c("Diabetes", "HighBP", "HighChol", "CholCheck", "BMI", "Smoker",
"Stroke", "HeartDiseaseorAttack", "PhysActivity", "Fruits", "Veggies",
"HvyAlcoholConsump", "AnyHealthcare", "NoDocbcCost", "GenHlth",
"MentHlth", "PhysHlth", "DiffWalk", "Sex", "Age", "Education", "Income")
# Subset the data to include only the relevant columns
diabetesUS <- diabetesUS %>% select(all_of(relevant_columns))
# Renaming columns for easier access if needed (already consistent in this case)
names(diabetesUS) <- c("Diabetes", "HighBP", "HighChol", "CholCheck", "BMI", "Smoker",
"Stroke", "HeartDisease", "PhysActivity", "Fruit", "Veg", "Alcohol",
"HealthCoverage", "CostDoc", "GenHealth", "MentalHealth", "PhysicalHealth",
"DiffWalk", "Sex", "Age", "Education", "Income")
# Checking the structure again after subsetting and renaming
str(diabetesUS)
## Descriptive Statistics
summary(diabetesUS)
# Example of calculating mean and median for some key features
mean(diabetesUS$BMI)
median(diabetesUS$BMI)
# Example of a bar plot for the target variable distribution
ggplot(diabetesUS, aes(x=Diabetes)) + geom_bar()
# Example of a box plot for BMI by diabetes status
ggplot(diabetesUS, aes(x=Diabetes, y=BMI)) + geom_boxplot()
# Example of a scatter plot for Age vs BMI by diabetes status
ggplot(diabetesUS, aes(x=Age, y=BMI, color=Diabetes)) + geom_point()
# Split the data into training and testing sets
set.seed(123)
trainIndex <- createDataPartition(diabetesUS$Diabetes, p = .8,
list = FALSE,
times = 1)
diabetesTrain <- diabetesUS[ trainIndex,]
diabetesTest  <- diabetesUS[-trainIndex,]
# Logistic regression model
logistic_model <- glm(Diabetes ~ ., data = diabetesTrain, family = binomial)
summary(logistic_model)
# Predictions on the test set
logistic_pred <- predict(logistic_model, diabetesTest, type = "response")
logistic_pred_class <- ifelse(logistic_pred > 0.5, 1, 0)
# Confusion matrix
confusionMatrix(as.factor(logistic_pred_class), diabetesTest$Diabetes)
# Load necessary libraries
library(nnet)
# Split the data into training and testing sets
set.seed(123)
trainIndex <- createDataPartition(diabetes_data$Diabetes, p = .8,
list = FALSE,
times = 1)
diabetesTrain <- diabetes_data[ trainIndex,]
diabetesTest  <- diabetes_data[-trainIndex,]
# Check the structure of the training data
str(diabetesTrain)
# Load necessary libraries
library(nnet)
# Split the data into training and testing sets
set.seed(123)
trainIndex <- createDataPartition(diabetesUS$Diabetes, p = .8,
list = FALSE,
times = 1)
diabetesTrain <- diabetes_data[ trainIndex,]
diabetesTest  <- diabetes_data[-trainIndex,]
# Check the structure of the training data
str(diabetesTrain)
# Load necessary libraries
library(nnet)
# Split the data into training and testing sets
set.seed(123)
trainIndex <- createDataPartition(diabetesUS$Diabetes, p = .8,
list = FALSE,
times = 1)
diabetesTrain <- diabetesUS[ trainIndex,]
diabetesTest  <- diabetesUS[-trainIndex,]
# Check the structure of the training data
str(diabetesTrain)
# Fit the multinomial logistic regression model
multinom_model <- multinom(Diabetes ~ ., data = diabetesTrain)
# Summary of the model
summary(multinom_model)
# Predict the probabilities
multinom_pred <- predict(multinom_model, diabetesTest, type = "probs")
# Predict the class with the highest probability
multinom_pred_class <- apply(multinom_pred, 1, which.max) - 1
# Convert predictions to factor to match levels of actual data
multinom_pred_class <- as.factor(multinom_pred_class)
# Confusion matrix
confusionMatrix(multinom_pred_class, diabetesTest$Diabetes)
knitr::opts_chunk$set(echo = TRUE)
# Load necessary libraries
library(tidyverse)
library(caret)
# Import the data
diabetesUS <- read.csv("data_input/diabetes_012_health_indicators_BRFSS2015.csv")
# Display the first few rows of the data
head(diabetesUS)
tail(diabetesUS)
dim(diabetesUS)
names(diabetesUS)
# Checking data types and converting to appropriate types
str(diabetesUS)
# Checking for missing values
colSums(is.na(diabetesUS))
anyNA(diabetesUS)
# Converting target variable to factor
diabetesUS$Diabetes_012 <- as.factor(diabetesUS$Diabetes_012)
str(diabetesUS)
# Renaming target variable for consistency
names(diabetesUS)[names(diabetesUS) == "Diabetes_012"] <- "Diabetes"
# Selecting and renaming relevant columns based on their actual names in the dataset
relevant_columns <- c("Diabetes", "HighBP", "HighChol", "CholCheck", "BMI", "Smoker",
"Stroke", "HeartDiseaseorAttack", "PhysActivity", "Fruits", "Veggies",
"HvyAlcoholConsump", "AnyHealthcare", "NoDocbcCost", "GenHlth",
"MentHlth", "PhysHlth", "DiffWalk", "Sex", "Age", "Education", "Income")
# Subset the data to include only the relevant columns
diabetesUS <- diabetesUS %>% select(all_of(relevant_columns))
# Renaming columns for easier access if needed (already consistent in this case)
names(diabetesUS) <- c("Diabetes", "HighBP", "HighChol", "CholCheck", "BMI", "Smoker",
"Stroke", "HeartDisease", "PhysActivity", "Fruit", "Veg", "Alcohol",
"HealthCoverage", "CostDoc", "GenHealth", "MentalHealth", "PhysicalHealth",
"DiffWalk", "Sex", "Age", "Education", "Income")
# Checking the structure again after subsetting and renaming
str(diabetesUS)
## Descriptive Statistics
summary(diabetesUS)
# Example of calculating mean and median for some key features
mean(diabetesUS$BMI)
median(diabetesUS$BMI)
# Example of a bar plot for the target variable distribution
ggplot(diabetesUS, aes(x=Diabetes)) + geom_bar()
# Example of a box plot for BMI by diabetes status
ggplot(diabetesUS, aes(x=Diabetes, y=BMI)) + geom_boxplot()
# Example of a scatter plot for Age vs BMI by diabetes status
ggplot(diabetesUS, aes(x=Age, y=BMI, color=Diabetes)) + geom_point()
# Load necessary libraries
library(nnet)
# Split the data into training and testing sets
set.seed(123)
trainIndex <- createDataPartition(diabetesUS$Diabetes, p = .8,
list = FALSE,
times = 1)
diabetesTrain <- diabetesUS[ trainIndex,]
diabetesTest  <- diabetesUS[-trainIndex,]
# Check the structure of the training data
str(diabetesTrain)
# Fit the multinomial logistic regression model
multinom_model <- multinom(Diabetes ~ ., data = diabetesTrain)
# Summary of the model
summary(multinom_model)
# Predict the probabilities
multinom_pred <- predict(multinom_model, diabetesTest, type = "probs")
# Predict the class with the highest probability
multinom_pred_class <- apply(multinom_pred, 1, which.max) - 1
# Convert predictions to factor to match levels of actual data
multinom_pred_class <- as.factor(multinom_pred_class)
# Confusion matrix
confusionMatrix(multinom_pred_class, diabetesTest$Diabetes)
# Predict the probabilities
multinom_pred <- predict(multinom_model, diabetesTest, type = "probs")
# Predict the class with the highest probability
multinom_pred_class <- apply(multinom_pred, 1, which.max) - 1
# Convert predictions to factor to match levels of actual data
multinom_pred_class <- factor(multinom_pred_class, levels = levels(diabetesTest$Diabetes))
# Confusion matrix
confusionMatrix(multinom_pred_class, diabetesTest$Diabetes)
## Recursive Feature Elimination
# Take a random sample of the data for feature selection
set.seed(123)
sample_index <- sample(nrow(diabetes_data), 10000)
diabetes_sample <- diabetes_data[sample_index,]
# Split the sample data into training and testing sets
set.seed(123)
trainIndex <- createDataPartition(diabetes_sample$Diabetes, p = .8,
list = FALSE,
times = 1)
diabetesTrain <- diabetes_sample[ trainIndex,]
diabetesTest  <- diabetes_sample[-trainIndex,]
# RFE control settings
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# Perform Recursive Feature Elimination
results <- rfe(diabetesTrain[, -1], diabetesTrain$Diabetes, sizes=c(1:10), rfeControl=control)
# Print and plot the results
print(results)
predictors(results)
plot(results, type=c("g", "o"))
## Recursive Feature Elimination
# Take a random sample of the data for feature selection
set.seed(123)
sample_index <- sample(nrow(diabetesUS), 10000)
diabetes_sample <- diabetesUS[sample_index,]
# Split the sample data into training and testing sets
set.seed(123)
trainIndex <- createDataPartition(diabetes_sample$Diabetes, p = .8,
list = FALSE,
times = 1)
diabetesTrain <- diabetes_sample[ trainIndex,]
diabetesTest  <- diabetes_sample[-trainIndex,]
# RFE control settings
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# Perform Recursive Feature Elimination
results <- rfe(diabetesTrain[, -1], diabetesTrain$Diabetes, sizes=c(1:10), rfeControl=control)
# Print and plot the results
print(results)
predictors(results)
plot(results, type=c("g", "o"))
# Example of a bar plot for the target variable distribution
ggplot(diabetesUS, aes(x=Diabetes)) + geom_bar()
# Example of a box plot for BMI by diabetes status
ggplot(diabetesUS, aes(x=Diabetes, y=BMI)) + geom_boxplot()
# Example of a scatter plot for Age vs BMI by diabetes status
ggplot(diabetesUS, aes(x=Age, y=BMI, color=Diabetes)) + geom_point()
# Perform Recursive Feature Elimination
results <- rfe(diabetesTrain[, -1], diabetesTrain$Diabetes, sizes=c(1:10), rfeControl=control)
# Print and plot the results
print(results)
predictors(results)
plot(results, type=c("g", "o"))
knitr::opts_chunk$set(echo = TRUE)
# Load necessary libraries
library(tidyverse)
library(caret)
# Import the data
diabetesUS <- read.csv("data_input/diabetes_012_health_indicators_BRFSS2015.csv")
# Display the first few rows of the data
head(diabetesUS)
tail(diabetesUS)
dim(diabetesUS)
names(diabetesUS)
# Checking data types and converting to appropriate types
str(diabetesUS)
# Checking for missing values
colSums(is.na(diabetesUS))
anyNA(diabetesUS)
# Converting target variable to factor
diabetesUS$Diabetes_012 <- as.factor(diabetesUS$Diabetes_012)
str(diabetesUS)
# Renaming target variable for consistency
names(diabetesUS)[names(diabetesUS) == "Diabetes_012"] <- "Diabetes"
# Selecting and renaming relevant columns based on their actual names in the dataset
relevant_columns <- c("Diabetes", "HighBP", "HighChol", "CholCheck", "BMI", "Smoker",
"Stroke", "HeartDiseaseorAttack", "PhysActivity", "Fruits", "Veggies",
"HvyAlcoholConsump", "AnyHealthcare", "NoDocbcCost", "GenHlth",
"MentHlth", "PhysHlth", "DiffWalk", "Sex", "Age", "Education", "Income")
# Subset the data to include only the relevant columns
diabetesUS <- diabetesUS %>% select(all_of(relevant_columns))
# Renaming columns for easier access if needed (already consistent in this case)
names(diabetesUS) <- c("Diabetes", "HighBP", "HighChol", "CholCheck", "BMI", "Smoker",
"Stroke", "HeartDisease", "PhysActivity", "Fruit", "Veg", "Alcohol",
"HealthCoverage", "CostDoc", "GenHealth", "MentalHealth", "PhysicalHealth",
"DiffWalk", "Sex", "Age", "Education", "Income")
# Checking the structure again after subsetting and renaming
str(diabetesUS)
## Descriptive Statistics
summary(diabetesUS)
# Example of calculating mean and median for some key features
mean(diabetesUS$BMI)
median(diabetesUS$BMI)
# Example of a bar plot for the target variable distribution
ggplot(diabetesUS, aes(x=Diabetes)) + geom_bar()
# Example of a box plot for BMI by diabetes status
ggplot(diabetesUS, aes(x=Diabetes, y=BMI)) + geom_boxplot()
# Example of a scatter plot for Age vs BMI by diabetes status
ggplot(diabetesUS, aes(x=Age, y=BMI, color=Diabetes)) + geom_point()
# Load necessary libraries
library(nnet)
# Split the data into training and testing sets
set.seed(123)
trainIndex <- createDataPartition(diabetesUS$Diabetes, p = .8,
list = FALSE,
times = 1)
diabetesTrain <- diabetesUS[ trainIndex,]
diabetesTest  <- diabetesUS[-trainIndex,]
# Check the structure of the training data
str(diabetesTrain)
# Fit the multinomial logistic regression model
multinom_model <- multinom(Diabetes ~ ., data = diabetesTrain)
# Summary of the model
summary(multinom_model)
# Predict the probabilities
multinom_pred <- predict(multinom_model, diabetesTest, type = "probs")
# Predict the class with the highest probability
multinom_pred_class <- apply(multinom_pred, 1, which.max) - 1
# Convert predictions to factor to match levels of actual data
multinom_pred_class <- factor(multinom_pred_class, levels = levels(diabetesTest$Diabetes))
# Confusion matrix
confusionMatrix(multinom_pred_class, diabetesTest$Diabetes)
## Recursive Feature Elimination
# Take a random sample of the data for feature selection
set.seed(123)
sample_index <- sample(nrow(diabetesUS), 10000)
diabetes_sample <- diabetesUS[sample_index,]
# Split the sample data into training and testing sets
set.seed(123)
trainIndex <- createDataPartition(diabetes_sample$Diabetes, p = .8,
list = FALSE,
times = 1)
diabetesTrain <- diabetes_sample[ trainIndex,]
diabetesTest  <- diabetes_sample[-trainIndex,]
# RFE control settings
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# Perform Recursive Feature Elimination
results <- rfe(diabetesTrain[, -1], diabetesTrain$Diabetes, sizes=c(1:10), rfeControl=control)
# Print and plot the results
print(results)
predictors(results)
plot(results, type=c("g", "o"))
# Bar Plot for the Target Variable (Diabetes)
ggplot(diabetesUS, aes(x=Diabetes)) +
geom_bar(fill="steelblue") +
geom_text(stat='count', aes(label=scales::percent(..count../sum(..count..))),
vjust=-0.5, color="black") +
labs(title="Distribution of Diabetes Classes", x="Diabetes Status", y="Count") +
theme_minimal()
# Box Plot for BMI by Diabetes Status
ggplot(diabetesUS, aes(x=Diabetes, y=BMI, fill=Diabetes)) +
geom_boxplot(outlier.colour="red", outlier.shape=16, outlier.size=2) +
scale_fill_manual(values=c("0"="lightblue", "1"="lightgreen", "2"="lightcoral")) +
labs(title="BMI Distribution by Diabetes Status", x="Diabetes Status", y="BMI") +
theme_minimal()
# Scatter Plot of Age vs. BMI by Diabetes Status
ggplot(diabetesUS, aes(x=Age, y=BMI, color=Diabetes)) +
geom_jitter(alpha=0.6) +
geom_smooth(method='loess', se=FALSE) +
scale_color_manual(values=c("0"="lightblue", "1"="lightgreen", "2"="lightcoral")) +
labs(title="Age vs BMI by Diabetes Status", x="Age", y="BMI") +
theme_minimal()
# Physical Activity and BMI
ggplot(diabetesUS, aes(x=PhysActivity, y=BMI, fill=Diabetes)) +
geom_boxplot(outlier.colour="red", outlier.shape=16, outlier.size=2) +
facet_wrap(~ Diabetes) +
scale_fill_manual(values=c("0"="lightblue", "1"="lightgreen", "2"="lightcoral")) +
labs(title="BMI by Physical Activity and Diabetes Status", x="Physical Activity", y="BMI") +
theme_minimal()
